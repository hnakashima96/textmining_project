{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hirom\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#preprocessing\n",
    "import string\n",
    "\n",
    "#translation \n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from gensim import models\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#visualization \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base: https://medium.com/@adriensieg/text-similarities-da019229c894"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REF: \n",
    "    \n",
    "https://arxiv.org/pdf/1301.3781.pdf\n",
    "    \n",
    "https://www.aclweb.org/anthology/N19-1181.pdf\n",
    "    \n",
    "http://proceedings.mlr.press/v37/kusnerb15.pdf\n",
    "\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37842.pdf\n",
    "\n",
    "https://arxiv.org/pdf/1609.08144.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\hirom\\OneDrive - NOVAIMS\\NOVA IMS\\OneDrive_1_25-02-2021\\Text Mining\\Project\\corpus\\de-en\\scores.csv\")\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21704, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21704.000000</td>\n",
       "      <td>21704.000000</td>\n",
       "      <td>21704.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000898</td>\n",
       "      <td>71.852890</td>\n",
       "      <td>1.502995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.855140</td>\n",
       "      <td>26.348469</td>\n",
       "      <td>0.810923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.806322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.499574</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.216756</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.640273</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.535434</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            z-score     avg-score    annotators\n",
       "count  21704.000000  21704.000000  21704.000000\n",
       "mean       0.000898     71.852890      1.502995\n",
       "std        0.855140     26.348469      0.810923\n",
       "min       -5.806322      0.000000      1.000000\n",
       "25%       -0.499574     56.000000      1.000000\n",
       "50%        0.216756     79.000000      1.000000\n",
       "75%        0.640273     94.000000      2.000000\n",
       "max        2.535434    100.000000      9.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"A Generation Is Protesting\" in Ethiopia, Long a U.S. Ally</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"A Square Meal\" is a feast of historical tidbits.</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"A cultural change, a mental change, a physical change,\" Bam said.</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"A lot of former customers got priced out of Williamsburg too,\" he said.</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"A lot of the stuff I get is late 60s, early 70s, things that came out when I was 11 or 12, things I was probably a bit too young to get,\" he says.</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You're not singing by yourself - and in a group of 50 people singing, who'll hear if a note's out here or there?</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube Gaming is owned by Google's parent company Alphabet.</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young people are particularly vulnerable to this.</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Your doctor will examine you to see if the problems have a physical cause.</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeiss Meditec produces devices and equipment for doctors' practices and clinics.</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    annotators\n",
       "translation                                                   \n",
       "\"A Generation Is Protesting\" in Ethiopia, Long ...           7\n",
       "\"A Square Meal\" is a feast of historical tidbits.            4\n",
       "\"A cultural change, a mental change, a physical...           4\n",
       "\"A lot of former customers got priced out of Wi...           5\n",
       "\"A lot of the stuff I get is late 60s, early 70...          10\n",
       "...                                                        ...\n",
       "You're not singing by yourself - and in a group...           9\n",
       "YouTube Gaming is owned by Google's parent comp...           9\n",
       "Young people are particularly vulnerable to this.            5\n",
       "Your doctor will examine you to see if the prob...           6\n",
       "Zeiss Meditec produces devices and equipment fo...           5\n",
       "\n",
       "[3001 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df, values = 'annotators', index =['translation'], aggfunc = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference =df['reference']\n",
    "translation = df['translation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source         0\n",
       "reference      0\n",
       "translation    0\n",
       "z-score        0\n",
       "avg-score      0\n",
       "annotators     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(column):\n",
    "    pp_column = []\n",
    "    for sentence in column:\n",
    "        #exclude punctuation \n",
    "        sentence = re.sub(r'[^A-Za-z0-9]',' ',sentence)\n",
    "        #transform everything in lowercase\n",
    "        sentence = sentence.lower()\n",
    "        pp_column.append(sentence)\n",
    "        \n",
    "    processed = pd.Series(pp_column)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_reference = preprocessing(reference)\n",
    "p_translation = preprocessing(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = pd.concat([df_cp,p_reference.rename('p_reference')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp = pd.concat([df_cp,p_translation.rename('p_translation')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "      <th>p_reference</th>\n",
       "      <th>p_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>her timeless pace measures them when they equi...</td>\n",
       "      <td>their slow speed was measured by researchers o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "      <td>he said the areas offer quiet meeting points b...</td>\n",
       "      <td>he said the spaces provided calm meeting point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>for businessmen at the b 27  it s only a small...</td>\n",
       "      <td>this is only a small consolation for businesse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "      <td>this ability may be born or developed with gen...</td>\n",
       "      <td>this ability may be innate  or may develop as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "\n",
       "   annotators                                        p_reference  \\\n",
       "0           1  her timeless pace measures them when they equi...   \n",
       "1           2  he said the areas offer quiet meeting points b...   \n",
       "2           1  for businessmen at the b 27  it s only a small...   \n",
       "3           2  this ability may be born or developed with gen...   \n",
       "\n",
       "                                       p_translation  \n",
       "0  their slow speed was measured by researchers o...  \n",
       "1  he said the spaces provided calm meeting point...  \n",
       "2  this is only a small consolation for businesse...  \n",
       "3  this ability may be innate  or may develop as ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cp.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source            Olympia: Dreister Betrug bei Doping-Test\n",
       "reference           Olympia: threesty fraud in doping test\n",
       "translation      Olympics: Brazen cheating in doping tests\n",
       "z-score                                          -0.980437\n",
       "avg-score                                               39\n",
       "annotators                                               1\n",
       "p_reference         olympia  threesty fraud in doping test\n",
       "p_translation    olympics  brazen cheating in doping tests\n",
       "Name: 21, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cp.iloc[21,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "      <th>p_reference</th>\n",
       "      <th>p_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympia: threesty fraud in doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>-0.980437</td>\n",
       "      <td>39.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympia  threesty fraud in doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympia: Brazen fraud with doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>0.582416</td>\n",
       "      <td>95.25</td>\n",
       "      <td>4</td>\n",
       "      <td>olympia  brazen fraud with doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympia: Three scams on doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>-0.085961</td>\n",
       "      <td>73.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympia  three scams on doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympia: Trieste cheating on doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>-0.594918</td>\n",
       "      <td>43.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympia  trieste cheating on doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympia: Brazen fraud in doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>0.758588</td>\n",
       "      <td>95.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympia  brazen fraud in doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympia: Dreist fraud in doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>0.317103</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympia  dreist fraud in doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15245</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympics: triple fraud in doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>0.099333</td>\n",
       "      <td>77.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympics  triple fraud in doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21368</th>\n",
       "      <td>Olympia: Dreister Betrug bei Doping-Test</td>\n",
       "      <td>Olympics: Triple fraud in doping test</td>\n",
       "      <td>Olympics: Brazen cheating in doping tests</td>\n",
       "      <td>-1.098754</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>olympics  triple fraud in doping test</td>\n",
       "      <td>olympics  brazen cheating in doping tests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source  \\\n",
       "21     Olympia: Dreister Betrug bei Doping-Test   \n",
       "2240   Olympia: Dreister Betrug bei Doping-Test   \n",
       "4775   Olympia: Dreister Betrug bei Doping-Test   \n",
       "6867   Olympia: Dreister Betrug bei Doping-Test   \n",
       "8509   Olympia: Dreister Betrug bei Doping-Test   \n",
       "13797  Olympia: Dreister Betrug bei Doping-Test   \n",
       "15245  Olympia: Dreister Betrug bei Doping-Test   \n",
       "21368  Olympia: Dreister Betrug bei Doping-Test   \n",
       "\n",
       "                                      reference  \\\n",
       "21       Olympia: threesty fraud in doping test   \n",
       "2240     Olympia: Brazen fraud with doping test   \n",
       "4775        Olympia: Three scams on doping test   \n",
       "6867   Olympia: Trieste cheating on doping test   \n",
       "8509       Olympia: Brazen fraud in doping test   \n",
       "13797      Olympia: Dreist fraud in doping test   \n",
       "15245     Olympics: triple fraud in doping test   \n",
       "21368     Olympics: Triple fraud in doping test   \n",
       "\n",
       "                                     translation   z-score  avg-score  \\\n",
       "21     Olympics: Brazen cheating in doping tests -0.980437      39.00   \n",
       "2240   Olympics: Brazen cheating in doping tests  0.582416      95.25   \n",
       "4775   Olympics: Brazen cheating in doping tests -0.085961      73.00   \n",
       "6867   Olympics: Brazen cheating in doping tests -0.594918      43.00   \n",
       "8509   Olympics: Brazen cheating in doping tests  0.758588      95.00   \n",
       "13797  Olympics: Brazen cheating in doping tests  0.317103      76.00   \n",
       "15245  Olympics: Brazen cheating in doping tests  0.099333      77.00   \n",
       "21368  Olympics: Brazen cheating in doping tests -1.098754      25.00   \n",
       "\n",
       "       annotators                               p_reference  \\\n",
       "21              1    olympia  threesty fraud in doping test   \n",
       "2240            4    olympia  brazen fraud with doping test   \n",
       "4775            1       olympia  three scams on doping test   \n",
       "6867            1  olympia  trieste cheating on doping test   \n",
       "8509            1      olympia  brazen fraud in doping test   \n",
       "13797           1      olympia  dreist fraud in doping test   \n",
       "15245           1     olympics  triple fraud in doping test   \n",
       "21368           1     olympics  triple fraud in doping test   \n",
       "\n",
       "                                   p_translation  \n",
       "21     olympics  brazen cheating in doping tests  \n",
       "2240   olympics  brazen cheating in doping tests  \n",
       "4775   olympics  brazen cheating in doping tests  \n",
       "6867   olympics  brazen cheating in doping tests  \n",
       "8509   olympics  brazen cheating in doping tests  \n",
       "13797  olympics  brazen cheating in doping tests  \n",
       "15245  olympics  brazen cheating in doping tests  \n",
       "21368  olympics  brazen cheating in doping tests  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = df_cp[df_cp['p_translation'] == 'olympics  brazen cheating in doping tests']\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olympia  threesty fraud in doping test',\n",
       " 'olympia  brazen fraud with doping test',\n",
       " 'olympia  three scams on doping test',\n",
       " 'olympia  trieste cheating on doping test',\n",
       " 'olympia  brazen fraud in doping test',\n",
       " 'olympia  dreist fraud in doping test',\n",
       " 'olympics  triple fraud in doping test',\n",
       " 'olympics  triple fraud in doping test']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = teste['p_reference'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand = 'olympics  brazen cheating in doping tests'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REF: https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "\n",
    "The cosine similarity is advantageous because even if the two similar documents are far apart by the Euclidean distance (due to the size of the document), chances are they may still be oriented closer together. The smaller the angle, higher the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olympia  threesty fraud in doping test'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'olympics  brazen cheating in doping tests'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix = count_vectorizer.fit_transform([ref[0],cand])\n",
    "sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33333333],\n",
       "       [0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix6 = count_vectorizer.fit_transform([ref[6],cand])\n",
    "sparse_matrix6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  1.0  0.5\n",
       "1  0.5  1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cosine_similarity(sparse_matrix6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "def get_result(content_a, content_b):\n",
    "    text1 = content_a\n",
    "    text2 = content_b\n",
    "\n",
    "    vector1 = text_to_vector(text1)\n",
    "    vector2 = text_to_vector(text2)\n",
    "\n",
    "    cosine_result = get_cosine(vector1, vector2)\n",
    "    return cosine_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(ref[0],cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000000000000001"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_result(ref[6],cand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation** : A cosine value of 0 means that the two vectors are at 90 degrees to each other (orthogonal) and have no match. The closer the cosine value to 1, the smaller the angle and the greater the match between vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Mover Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REF: https://towardsdatascience.com/word-movers-distance-for-text-similarity-7492aeca71b0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_f = 'olympics  brazen cheating in doping tests'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries \n",
    "from time import time \n",
    "#remove stop words \n",
    "import os\n",
    "from gensim import models\n",
    "import gensim.downloader as api\n",
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized data \n",
    "def delete_sw(lista):\n",
    "    stop_words = stopwords.words('english')\n",
    "    finalresult = []\n",
    "    for sentence in lista:\n",
    "        processed = sentence.split()\n",
    "        clean = []\n",
    "        for word in processed:\n",
    "            if word not in stop_words:\n",
    "                clean.append(word)\n",
    "        finalresult.append(clean)\n",
    "    return finalresult "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ref = delete_sw(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cand = [w for w in cand_f if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ref = delete_sw(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['olympia', 'threesty', 'fraud', 'doping', 'test'],\n",
       " ['olympia', 'brazen', 'fraud', 'doping', 'test'],\n",
       " ['olympia', 'three', 'scams', 'doping', 'test'],\n",
       " ['olympia', 'trieste', 'cheating', 'doping', 'test'],\n",
       " ['olympia', 'brazen', 'fraud', 'doping', 'test'],\n",
       " ['olympia', 'dreist', 'fraud', 'doping', 'test'],\n",
       " ['olympics', 'triple', 'fraud', 'doping', 'test'],\n",
       " ['olympics', 'triple', 'fraud', 'doping', 'test']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = model.wmdistance(clean_ref[0],clean_cand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/word-distance-between-word-embeddings-cc3e9cf1d632\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_wmd.html\n",
    "    \n",
    "The sentence can have no similar words, but by the relevand words in each sentence, it's possible to identify the \"semantical distance\" between them. \n",
    "With this method we can evaluate how the reference of translation is close to the real translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['olympia', 'threesty', 'fraud', 'doping', 'test'],\n",
       " ['olympia', 'brazen', 'fraud', 'doping', 'test'],\n",
       " ['olympia', 'three', 'scams', 'doping', 'test'],\n",
       " ['olympia', 'trieste', 'cheating', 'doping', 'test'],\n",
       " ['olympia', 'brazen', 'fraud', 'doping', 'test'],\n",
       " ['olympia', 'dreist', 'fraud', 'doping', 'test'],\n",
       " ['olympics', 'triple', 'fraud', 'doping', 'test'],\n",
       " ['olympics', 'triple', 'fraud', 'doping', 'test']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olympics', 'brazen', 'cheating', 'doping', 'tests']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289396995482206"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5927309122713804"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance6 = model.wmdistance(clean_ref[6],clean_cand)\n",
    "distance6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: more similar words between sentences, less distant they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD the embedding comparation in the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp['cos_similarity'] = df_cp.apply(lambda x:get_result(x['p_reference'],x['p_translation']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp['WMD'] = df_cp.apply(lambda x:model.wmdistance(x['p_reference'],x['p_translation']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "      <th>p_reference</th>\n",
       "      <th>p_translation</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>WMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>her timeless pace measures them when they equi...</td>\n",
       "      <td>their slow speed was measured by researchers o...</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.216127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "      <td>he said the areas offer quiet meeting points b...</td>\n",
       "      <td>he said the spaces provided calm meeting point...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.153579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>for businessmen at the b 27  it s only a small...</td>\n",
       "      <td>this is only a small consolation for businesse...</td>\n",
       "      <td>0.679366</td>\n",
       "      <td>0.110323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "      <td>this ability may be born or developed with gen...</td>\n",
       "      <td>this ability may be innate  or may develop as ...</td>\n",
       "      <td>0.553399</td>\n",
       "      <td>0.197048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "      <td>because they prefer water temperatures around ...</td>\n",
       "      <td>they generally only come to the surface in win...</td>\n",
       "      <td>0.783547</td>\n",
       "      <td>0.077533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21699</th>\n",
       "      <td>Lt. Cmdr. Patrick Evans, ein Pressesprecher de...</td>\n",
       "      <td>Lt. Cmdr. Patrick Evans, a press officer at th...</td>\n",
       "      <td>Lt. Cmdr. Patrick Evans, a Pentagon spokesman,...</td>\n",
       "      <td>1.246459</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lt  cmdr  patrick evans  a press officer at th...</td>\n",
       "      <td>lt  cmdr  patrick evans  a pentagon spokesman ...</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.066873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21700</th>\n",
       "      <td>\"Um ein Beispiel zu geben: Wenn ich ihn etwas ...</td>\n",
       "      <td>\"To give an example: If I ask him something th...</td>\n",
       "      <td>\"To give an example: If I ask him what happene...</td>\n",
       "      <td>0.792878</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>to give an example  if i ask him something th...</td>\n",
       "      <td>to give an example  if i ask him what happene...</td>\n",
       "      <td>0.724569</td>\n",
       "      <td>0.104635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21701</th>\n",
       "      <td>Ein Grund dafür, dass nicht alle Nachbarn das ...</td>\n",
       "      <td>One reason that not all neighbours view this a...</td>\n",
       "      <td>One reason for not all neighbours seeing this ...</td>\n",
       "      <td>0.597068</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>one reason that not all neighbours view this a...</td>\n",
       "      <td>one reason for not all neighbours seeing this ...</td>\n",
       "      <td>0.814174</td>\n",
       "      <td>0.088088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21702</th>\n",
       "      <td>Der Gewinn vor Zinsen und Steuern erhöhte sich...</td>\n",
       "      <td>Profit before interest and tax increased from ...</td>\n",
       "      <td>Profits before interest and taxes increased fr...</td>\n",
       "      <td>-0.305719</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>profit before interest and tax increased from ...</td>\n",
       "      <td>profits before interest and taxes increased fr...</td>\n",
       "      <td>0.729397</td>\n",
       "      <td>0.100805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21703</th>\n",
       "      <td>Großbritannien und die Vereinigten Staaten wer...</td>\n",
       "      <td>Britain and the United States will clash on Sa...</td>\n",
       "      <td>Britain and the United States will meet on Sat...</td>\n",
       "      <td>0.995212</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>britain and the united states will clash on sa...</td>\n",
       "      <td>britain and the united states will meet on sat...</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.070839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21704 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0      Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1      Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2      Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3      Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4      Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "...                                                  ...   \n",
       "21699  Lt. Cmdr. Patrick Evans, ein Pressesprecher de...   \n",
       "21700  \"Um ein Beispiel zu geben: Wenn ich ihn etwas ...   \n",
       "21701  Ein Grund dafür, dass nicht alle Nachbarn das ...   \n",
       "21702  Der Gewinn vor Zinsen und Steuern erhöhte sich...   \n",
       "21703  Großbritannien und die Vereinigten Staaten wer...   \n",
       "\n",
       "                                               reference  \\\n",
       "0      Her timeless pace measures them when they equi...   \n",
       "1      He said the areas offer quiet meeting points b...   \n",
       "2      For businessmen at the B 27, it's only a small...   \n",
       "3      This ability may be born or developed with gen...   \n",
       "4      Because they prefer water temperatures around ...   \n",
       "...                                                  ...   \n",
       "21699  Lt. Cmdr. Patrick Evans, a press officer at th...   \n",
       "21700  \"To give an example: If I ask him something th...   \n",
       "21701  One reason that not all neighbours view this a...   \n",
       "21702  Profit before interest and tax increased from ...   \n",
       "21703  Britain and the United States will clash on Sa...   \n",
       "\n",
       "                                             translation   z-score  avg-score  \\\n",
       "0      Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1      He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2      This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3      This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4      They generally only come to the surface in win...  0.293909       87.0   \n",
       "...                                                  ...       ...        ...   \n",
       "21699  Lt. Cmdr. Patrick Evans, a Pentagon spokesman,...  1.246459      100.0   \n",
       "21700  \"To give an example: If I ask him what happene...  0.792878       98.0   \n",
       "21701  One reason for not all neighbours seeing this ...  0.597068       76.0   \n",
       "21702  Profits before interest and taxes increased fr... -0.305719       61.0   \n",
       "21703  Britain and the United States will meet on Sat...  0.995212       97.0   \n",
       "\n",
       "       annotators                                        p_reference  \\\n",
       "0               1  her timeless pace measures them when they equi...   \n",
       "1               2  he said the areas offer quiet meeting points b...   \n",
       "2               1  for businessmen at the b 27  it s only a small...   \n",
       "3               2  this ability may be born or developed with gen...   \n",
       "4               2  because they prefer water temperatures around ...   \n",
       "...           ...                                                ...   \n",
       "21699           1  lt  cmdr  patrick evans  a press officer at th...   \n",
       "21700           1   to give an example  if i ask him something th...   \n",
       "21701           1  one reason that not all neighbours view this a...   \n",
       "21702           1  profit before interest and tax increased from ...   \n",
       "21703           1  britain and the united states will clash on sa...   \n",
       "\n",
       "                                           p_translation  cos_similarity  \\\n",
       "0      their slow speed was measured by researchers o...        0.258199   \n",
       "1      he said the spaces provided calm meeting point...        0.750000   \n",
       "2      this is only a small consolation for businesse...        0.679366   \n",
       "3      this ability may be innate  or may develop as ...        0.553399   \n",
       "4      they generally only come to the surface in win...        0.783547   \n",
       "...                                                  ...             ...   \n",
       "21699  lt  cmdr  patrick evans  a pentagon spokesman ...        0.802260   \n",
       "21700   to give an example  if i ask him what happene...        0.724569   \n",
       "21701  one reason for not all neighbours seeing this ...        0.814174   \n",
       "21702  profits before interest and taxes increased fr...        0.729397   \n",
       "21703  britain and the united states will meet on sat...        0.956522   \n",
       "\n",
       "            WMD  \n",
       "0      0.216127  \n",
       "1      0.153579  \n",
       "2      0.110323  \n",
       "3      0.197048  \n",
       "4      0.077533  \n",
       "...         ...  \n",
       "21699  0.066873  \n",
       "21700  0.104635  \n",
       "21701  0.088088  \n",
       "21702  0.100805  \n",
       "21703  0.070839  \n",
       "\n",
       "[21704 rows x 10 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cp[['cos_similarity','WMD']]\n",
    "y = df_cp['z-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "    \n",
    "#https://medium.com/codex/step-by-step-guide-to-simple-and-multiple-linear-regression-in-python-867ac9a30298    \n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the difference in argument order\n",
    "model = LinearRegression().fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_slope = model.coef_\n",
    "slr_intercept = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08907757252656401"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08773109836871795"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT \n",
    "\n",
    "REF:https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#what-is-bert\n",
    "\n",
    "https://medium.com/analytics-vidhya/bert-word-embeddings-deep-dive-32f6214f02bf\n",
    "\n",
    "#libraries \n",
    "import torch\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from pytorch_transformers import BertModel\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def tokenize_bert(text):\n",
    "    lista = []\n",
    "    for sentence in text: \n",
    "        processed = tokenizer.tokenize(\"[CLS] \" + sentence + \" [SEP]\")\n",
    "        lista.append(processed)\n",
    "    return lista\n",
    "\n",
    "def convert(lst):\n",
    "      \n",
    "    return '/'.join(lst)\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_ref = tokenize_bert(ref)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_ref[0])\n",
    "indexed_tokens\n",
    "\n",
    "for tup in zip(tokenized_ref[0], indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
    "\n",
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_ref[0])\n",
    "segments_ids\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "tokens_tensor\n",
    "\n",
    "segments_tensors\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
